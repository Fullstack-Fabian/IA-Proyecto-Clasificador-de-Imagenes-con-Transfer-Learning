# ðŸ“¦ IA-Proyecto-Clasificador-de-Imagenes-con-Transfer-Learning

Este proyecto implementa un **clasificador de imÃ¡genes** usando *Transfer Learning* en TensorFlow/Keras.  
Para entrenar el modelo se requiere un **dataset grande**, el cual no estÃ¡ incluido directamente en GitHub por las limitaciones de tamaÃ±o (100MB por archivo).  

---
ðŸ“‚ Estructura del proyecto

IA-Proyecto-Clasificador-de-Imagenes-con-Transfer-Learning/
â”œâ”€â”€ data/                # Dataset (no subido a GitHub, se descarga de Drive)
â”œâ”€â”€ main.py              # Script principal
â”œâ”€â”€ model/               # Modelos entrenados
â”œâ”€â”€ requirements.txt     # Dependencias
â”œâ”€â”€ test_tf.py           # Script de prueba
â”œâ”€â”€ partir.sh            # Script para partir dataset
â”œâ”€â”€ recomponer.sh        # Script para recomponer dataset
â””â”€â”€ README.md            # DocumentaciÃ³n del proyecto
---

---

## ðŸš€ CÃ³mo usar el dataset

### 1. Descargar dataset partido
El dataset estÃ¡ dividido en varios archivos de 200MB y almacenado en Google Drive:  

ðŸ‘‰ [Descargar dataset desde Google Drive](https://drive.google.com/drive/folders/1tLNgk7UdlS-awAhWQxX06QT8b4g9X6Tb?usp=drive_link)

---

### 2. Recomponer el dataset
DespuÃ©s de descargar todas las partes (`archive_part_000`, `archive_part_001`, â€¦) mÃ©telas en una carpeta llamada `partes/` dentro del proyecto y corre:

```bash
bash recomponer.sh
```

### 3. Descomprimir dataset
unzip archive.zip -d data/

### 4. Notas importantes

No cambies el prefijo parte_, ya que el script los usa para unirlos.

AsegÃºrate de que todas las partes estÃ©n completas antes de recomponer.

El tamaÃ±o de las partes se puede ajustar en el parÃ¡metro -b 100M.

## ðŸ“œ Scripts incluidos
```bash
bash partir.sh
```
Divide un archivo grande en bloques de 200MB.

